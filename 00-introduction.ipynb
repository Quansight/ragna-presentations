{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an AI Document Inquiry Chat with Offline LLMs\n",
    "\n",
    "**Tutorial at PyCon US 2024**\n",
    "\n",
    "**Room: 321**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ragna-web-ui.gif\" width=80% />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenters üë©üèª‚Äçüè´\n",
    "\n",
    "<img src=\"images/quansight.png\" width=35% align=\"right\"/>\n",
    "\n",
    "* Pavithra Eswaramoorthy, [@pavithraes](https://github.com/pavithraes), Developer Advocate at Quansight\n",
    "* Dharhas Pothina, [@dharhas](https://github.com/dharhas), CTO at Quansight\n",
    "* Andrew Huang,[@ahuang11](https://github.com/ahuang11), Software Engineer at Anaconda\n",
    "\n",
    "## Setup üßë‚Äçüíª\n",
    "\n",
    "1. Go to [scipy.quansight.dev](https://pycon-tutorial.quansight.dev) and click on the [\"register here\"](https://scipy.quansight.dev/registration) link\n",
    "2. Register with an email address (this will be your `<username>`) and the Coupon provided. (We are not verifying emails, so this can be any email address)\n",
    "3. You will be given a temporary `<password>`\n",
    "4. Sign-in with your `<username>` and the temporary `<password>` provided. You will be prompted to change your password. \n",
    "5. Once logged in, Click on the JupyterLab card, and select and start the GPU server.\n",
    "6. In the left sidebar, navigate to `tutorial/00-introduction.ipynb` and follow along!\n",
    "\n",
    "‚òùüèº **Note:** Ensure you are using the `scipy-scipy-rags-to-riches` for all notebooks. This environment should be auto-selected for you.\n",
    "\n",
    "That's it, you can now follow along with the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's goals üéØ\n",
    "\n",
    "* Run a Large Language Model (LLM) in offline mode\n",
    "* Build a RAG-based chat function with Ragna's Python API, OpenAI's GPT 4, and a local LLM\n",
    "* Build and deploy a web application with Panel to interact with the LLM\n",
    "* Explore a Panel-based web app built with Ragna, and experiment with different options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "**‚ú® Next: [Set up an offline Large Language Model](01-local-llm.ipynb) ‚Üí**\n",
    "\n",
    "üí¨ _Wish to continue discussions after the tutorial? Contact the presenters: [@pavithraes](https://github.com/pavithraes), [@dharhas](https://github.com/dharhas), [@ahuang11](https://github.com/ahuang11)_\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scipy-scipy-rags-to-riches",
   "language": "python",
   "name": "conda-env-scipy-scipy-rags-to-riches-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
