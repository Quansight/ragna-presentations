{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ragna-logo.png\" width=30% align=\"right\"/>\n",
    "\n",
    "# Build an AI Document Inquiry Chat with Offline LLMs\n",
    "\n",
    "**Tutorial at PyCon DE & PyData Berlin 2024**\n",
    "\n",
    "**Room: A05-A06**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ragna-web-ui.gif\" width=80% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenters üë©üèª‚Äçüè´\n",
    "\n",
    "<img src=\"images/quansight.png\" width=35% align=\"right\"/>\n",
    "\n",
    "* Philip Meier, [@pmeier](https://github.com/pmeier), Senior Software Engineer at Quansight and creator of Ragna\n",
    "* Pavithra Eswaramoorthy, [@pavithraes](https://github.com/pavithraes), Developer Advocate at Quansight\n",
    "\n",
    "## Setup üßë‚Äçüíª\n",
    "\n",
    "1. Go to `pycon-tutorial.quansight.dev`\n",
    "2. Sign-in with a `<username>` and `<password>` provided\n",
    "3. Click on the JupyterLab card, and select and start the GPU server\n",
    "4. In the left sidebar, navigate to `tutorial/00-introduction.ipynb` and follow along!\n",
    "\n",
    "‚òùüèº **Note:** Ensure you are using the `global-global-pycon-de` for all notebooks. This environment should be auto-selected for you.\n",
    "\n",
    "That's it, you can now follow along with the tutorial.\n",
    "\n",
    "### Side note: What is Nebari - the platform we're using? ‚ÑπÔ∏è\n",
    "\n",
    "It's an open source data science platform. It is quick to deploy (by anyone) and ships with several useful features like environment management and dashboard deployment.\n",
    "\n",
    "üîó Learn more: [nebari.dev](https://nebari.dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's goals üéØ\n",
    "\n",
    "* Run a Large Language Model (LLM) in offline mode\n",
    "* Build a RAG-based chat function with Ragna's Python API\n",
    "* Experiment with different LLMs \n",
    "* Explore a Panel-based web app built with Ragna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "**‚ú® Next: [Set up an offline Large Language Model](01-local-llm.ipynb) ‚Üí**\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-global-pycon-de",
   "language": "python",
   "name": "conda-env-global-global-pycon-de-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
