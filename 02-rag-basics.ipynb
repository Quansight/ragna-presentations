{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15bbda72-2f2a-43d3-a3ed-b7f8c2f244a9",
   "metadata": {},
   "source": [
    "<img src=\"images/ragna-logo.png\" width=15% align=\"right\"/>\n",
    "\n",
    "# Basics of RAG-powered chat app\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba6e1b-e8ad-47c9-a9e4-48648fd476f1",
   "metadata": {},
   "source": [
    "## What is RAG?\n",
    "\n",
    "LLMs are trained on vast, but static datasets. This means, while they can predict answers for several general questions like:\n",
    "\n",
    "<img src=\"images/chatgpt-what-is-pyconde.png\" width=60%/>\n",
    "\n",
    "They can't answer or hallucinate answers for recent events or specific topics:\n",
    "\n",
    "<img src=\"images/chatpgt-when-is-pyconde.png\" width=60%/>\n",
    "\n",
    "Retrieval-augmented generation (RAG) is a method to augment foundational LLMs with contextual data (documents), to reduce hallucinations and get around the limited space available in an LLM prompts (around 3,000 words for ChatGPT 3.5).\n",
    "\n",
    "<img src=\"images/RAG-new.png\" width=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a1f1a5-cdef-4349-a69d-44cf0d81c487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## What is Ragna?\n",
    "\n",
    "Open source library for RAG Orchestration with a Python API, REST API, and web UI.\n",
    "\n",
    "<img src=\"images/ragna-architecture.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d45748-b244-4104-bc9a-3b744b4d10c9",
   "metadata": {},
   "source": [
    "## Build a chat function with Ragna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649a183-e6d9-4f92-96b1-c89d962fb3ca",
   "metadata": {},
   "source": [
    "### Step 0: Ragna configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd85f3-02d4-4b6f-a045-2495fce37c31",
   "metadata": {},
   "source": [
    "Create a `ragna.toml` file and copy the content from `shared/analyst/ragna.toml.tpl` file. Update the following fields with your Nebari username:\n",
    "\n",
    "* `local_root`\n",
    "* `api.root_path`\n",
    "* `database_url`\n",
    "* `ui.root_path`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae7dd0-bd7e-466d-bd47-7aa2a355e1a6",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "source": [
    "Using the configuration file, you can set the assistants, source storages, API endpoints, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca1a36-78dd-454c-a92b-317c4b53792d",
   "metadata": {},
   "source": [
    "To use default LLMs like OpenAI, you will need API keys. For this tutorial, we have included a key for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b4d2b-a758-46a6-92d1-6b099af640ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "dotenv_path = Path.home() / Path(\"shared/analyst/api-keys.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec7c65-7741-46ed-8454-115f97424784",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Aside: Local setup\n",
    "\n",
    "On local computers, follow these step to get started with Ragna:\n",
    "\n",
    "1. Install Ragna with pip or conda\n",
    "2. Run `ragna init` to create the `ragna.toml` config file with a guided CLI. \n",
    "3. Get an OpenAI API key at https://platform.openai.com/api-keys, and set the environment variable `export OPENAI_API_KEY=\"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f3695-9e43-4b1a-8d33-649f3c4449ec",
   "metadata": {},
   "source": [
    "### Step 1: Select relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b187fe-31f6-449a-bfec-bc3398dd43af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's use PyCon DE & PyData Berlin 2024's [FAQ](https://2024.pycon.de/frequently-asked-questions/#live-streams), and  [PyLadies](https://2024.pycon.de/blog/pyladies-at-pyconde-pydata/) pages.\n",
    "\n",
    "Note: There are more documents in the `/files` directory that you can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9865ffb-8436-4856-a46a-6f4448ed7d37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"files/pycon-de-faqs.pdf\",\n",
    "    \"files/pycon-de-pyladies.pdf\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e778ed8-3b35-48e0-9a01-ac17937b05fa",
   "metadata": {},
   "source": [
    "### Step 2: Select assistants and source storage\n",
    "\n",
    "ðŸ”— [Check the available assistants in the docs](https://ragna.chat/en/stable/generated/tutorials/gallery_python_api/#step-3-select-an-assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc39c85-65a1-4a58-97d7-ed6d5dcf7b1d",
   "metadata": {},
   "source": [
    "We are selecting OpenAI's GPT-3.5 and GPT-4 LLMs, and Chroma and LanceDB source storages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4d44b6-8d52-4e5e-a5e1-da566cea4407",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragna import Rag\n",
    "from ragna.assistants import Gpt4, Gpt35Turbo16k\n",
    "from ragna.source_storages import Chroma, LanceDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de4c14ab-d1e6-4c0a-a060-7dbefe10de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = Rag()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a4c3dc-2474-430c-be12-ec13b41458e0",
   "metadata": {},
   "source": [
    "### Step 3: Start chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb51db8-c455-416e-acd5-0d6888fde5ad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content=How can I help you with the documents?, role=MessageRole.SYSTEM, sources=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_gpt = rag.chat(\n",
    "    documents=documents,\n",
    "    source_storage=Chroma,\n",
    "    assistant=Gpt4,\n",
    ")\n",
    "\n",
    "await chat_gpt.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0f42c-d1fc-4e0f-899f-83a1e156557d",
   "metadata": {},
   "source": [
    "### Step 4: Ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4cc2cf6-b464-46f4-91f5-c123be434035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Response: \n",
      "\n",
      "The PyCon DE & PyData Berlin 2024 conference begins on April 22, 2024.\n"
     ]
    }
   ],
   "source": [
    "answer = await chat_gpt.answer(\"When is PyCon DE 2024?\")\n",
    "print(f\"\\nLLM Response: \\n\\n{answer.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f4dab-4a4c-49af-92af-ab3fbd675169",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Lets look at the sources used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e68c8887-b10d-4b21-bea1-fa950534387d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='4047c99f-246e-40a8-8c8a-b17662679593' document=<ragna.core.LocalDocument object at 0x7cff38275790> location='1, 2' content=\"\\uf0c9\\nPyLadies at PyCon DE &\\nPyData Berlin 2024\\nMAR 12, 2024 BY ORGANIZERS & PYLADIES\\nBecause diversity isn't supplementary, it's foundational.\\nThe PyLadies segment at this year's PyCon DE & PyData Berlin\\nconference is a collaboration with the PySV (Python Software Verband\\ne.V.) to foment diversity, inclusion, and belonging within the tech\\ncommunity. PyLadies is a global volunteer organization dedicated to\\nsupporting underestimated and underrepresented genders in tech,\\nincluding women, non-binary, and trans people, encouraging their\\nactive participation and leadership within the Python open-source\\necosystem. We aim to offer a safe, welcoming environment for all skill\\nlevels to learn, share, grow, and become today's and tomorrow's\\nleaders.\\n\\uf077\\nWe focus on uplifting women and gender-underrepresented groups.\\nFor those who do not identify with these groups, we appreciate your\\nactive allyship in recognizing and using your privileges to raise\\nopaqued voices and foster an inclusive environment by ensuring\\nequitable participation in discussions and events.\\nThis is a collective organization from PyLadies Germany chapters:\\nBerlin, Hamburg, Munich, SÃ¼dwest (Manheim, Heidelberg, Heilbronn,\\nStuttgart, and Karlsruhe) with PySV.\\nCollaborative Events at\\nPyCon DE & PyData Berlin\\n2024\\nHumble Data Workshop\\nSunday, April 21, 10:30 - 15:30\\nTailored for complete beginners, this workshop introduces the basics\\nof programming in Python, focusing on essential libraries and tools\\nsuch as Jupyter notebooks, pandas, and Matplotlib. Humble Data\\nfosters inclusivity and creates a safe, supportive community for\\nthose venturing into Python and Data Science.\\nhttps://humbledata.org/\\nF R E E  R E G I S T R A T I O N  ( U N T I L  M A R C H  2 9 T H )\\nWelcome Guided Tour\\nSunday, April 21, 17:00 - 19:00\\nAs a welcoming gesture, we invite conference participants, especially\\nthose new to the city, to visit some classic landmarks beginning with\\na visit to the Bundestag Dome. Here, you'll be treated to an audio-\\nguided tour (available in a wide range\" num_tokens=500\n"
     ]
    }
   ],
   "source": [
    "print(answer.sources[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "465bd78f-b700-43ec-923c-13329e725f05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Response: \n",
      "\n",
      "To participate in the lightning talks at PyCon DE, you need to sign up by putting your name and topic on the whiteboard next to the registration desk. The sign-up process is on a first-come-first-serve basis. The queue is reset every day in the morning. You can talk about almost anything, but promotions for products or companies, and 'we are hiring' calls are not allowed. Conference announcements are limited to one minute only. Each speaker is allowed one lightning talk per day. Any speaker who hasn't given a lightning talk at the conference is prioritized over those who have already given a talk.\n"
     ]
    }
   ],
   "source": [
    "answer = await chat_gpt.answer(\"How to participate in lightning talks at PyCon DE?\")\n",
    "print(f\"\\nLLM Response: \\n\\n{answer.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35313b3f-913d-4393-b310-b1b866d4921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Response: \n",
      "\n",
      "The PyLadies Lunch is scheduled for Tuesday, April 23, from 12:10 to 13:10.\n"
     ]
    }
   ],
   "source": [
    "answer = await chat_gpt.answer(\"When is the PyLadies lunch?\")\n",
    "print(f\"\\nLLM Response: \\n\\n{answer.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fedd4e7-95a5-4cc3-a97f-a9ed7ea562b6",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "**âœ¨ Next: [Use Local LLM with Ragna](03-RAG-local-llm.ipynb) â†’**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f52a32-b511-4971-a20f-60e5f7dc7c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-global-pycon-de",
   "language": "python",
   "name": "conda-env-global-global-pycon-de-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
