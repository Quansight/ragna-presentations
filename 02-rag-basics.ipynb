{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15bbda72-2f2a-43d3-a3ed-b7f8c2f244a9",
   "metadata": {},
   "source": [
    "<img src=\"images/ragna-logo.png\" width=\"200px\" align=\"right\"/>\n",
    "\n",
    "# Basics of RAG-powered chat app\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba6e1b-e8ad-47c9-a9e4-48648fd476f1",
   "metadata": {},
   "source": [
    "## What is Retrieval-augmented generation (RAG)?\n",
    "\n",
    "LLMs are trained on vast, but static datasets. This means, while they can predict answers for several general questions like:\n",
    "\n",
    "<img src=\"images/chatgpt-what-is-pycon-us.png\" width=60% style=\"border:1px solid black;\"/>\n",
    "\n",
    "They can't answer or hallucinate answers for recent events or specific topics:\n",
    "\n",
    "<img src=\"images/chatgpt-when-is-pycon-us.png\" width=50% style=\"border:1px solid black;\"/>\n",
    "\n",
    "**Retrieval-augmented generation (RAG)** is a method to augment foundational LLMs with **contextual data (documents)**, to reduce hallucinations and get around the limited space available in an LLM prompts (around 3,000 words for ChatGPT 3.5).\n",
    "\n",
    "<img src=\"images/RAG-new.png\" width=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a1f1a5-cdef-4349-a69d-44cf0d81c487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## What is Ragna?\n",
    "\n",
    "Open source library for RAG **Orchestration** with a Python API, REST API, and web UI.\n",
    "\n",
    "It gives you a convenience tools to quickly build RAG workflows and applications, with any LLM or source storage you prefer.\n",
    "\n",
    "<img src=\"images/ragna-architecture.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d45748-b244-4104-bc9a-3b744b4d10c9",
   "metadata": {},
   "source": [
    "## Build a chat function with Ragna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649a183-e6d9-4f92-96b1-c89d962fb3ca",
   "metadata": {},
   "source": [
    "### Step 0: Setup requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca1a36-78dd-454c-a92b-317c4b53792d",
   "metadata": {},
   "source": [
    "To use builtin LLMs like OpenAI, you will need API keys. For this tutorial, we have included a key for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050b4d2b-a758-46a6-92d1-6b099af640ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T11:33:43.185034Z",
     "iopub.status.busy": "2024-05-10T11:33:43.184145Z",
     "iopub.status.idle": "2024-05-10T11:33:43.191415Z",
     "shell.execute_reply": "2024-05-10T11:33:43.190515Z",
     "shell.execute_reply.started": "2024-05-10T11:33:43.185001Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "dotenv_path = Path.home() / Path(\"shared/analyst/.env\")\n",
    "assert load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec7c65-7741-46ed-8454-115f97424784",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Side note: Local setup instructions ðŸ’»\n",
    "\n",
    "On local computers, follow these step to get started with Ragna:\n",
    "\n",
    "1. Install Ragna: `pip install 'ragna[all]'`\n",
    "2. Run `ragna init` to create the `ragna.toml` config file with a guided CLI. \n",
    "3. [Get an OpenAI API key](https://platform.openai.com/api-keys) and set the relevant environment variable `export OPENAI_API_KEY=\"XXX\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f3695-9e43-4b1a-8d33-649f3c4449ec",
   "metadata": {},
   "source": [
    "### Step 1: Select relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b187fe-31f6-449a-bfec-bc3398dd43af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's use PyCon US 2024's [What is PyCon US?](https://us.pycon.org/2024/about/pycon/), and  [Onsite Information](https://us.pycon.org/2024/attend/onsite/) pages.\n",
    "\n",
    "ðŸ’¡ **Tip:** There are more documents in the `/files` directory that you can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9865ffb-8436-4856-a46a-6f4448ed7d37",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-05-10T11:39:34.983206Z",
     "iopub.status.busy": "2024-05-10T11:39:34.982165Z",
     "iopub.status.idle": "2024-05-10T11:39:34.987341Z",
     "shell.execute_reply": "2024-05-10T11:39:34.986301Z",
     "shell.execute_reply.started": "2024-05-10T11:39:34.983171Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"files/what-is-pycon-us.pdf\",\n",
    "    \"files/onsite-information.pdf\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e778ed8-3b35-48e0-9a01-ac17937b05fa",
   "metadata": {},
   "source": [
    "### Step 2: Select assistants and source storage\n",
    "\n",
    "ðŸ”— [Check the available assistants in the docs](https://ragna.chat/en/stable/generated/tutorials/gallery_python_api/#step-3-select-an-assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc39c85-65a1-4a58-97d7-ed6d5dcf7b1d",
   "metadata": {},
   "source": [
    "We are selecting OpenAI's GPT-3.5 and GPT-4 LLMs, and Chroma and LanceDB source storages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc4d44b6-8d52-4e5e-a5e1-da566cea4407",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-05-10T11:39:36.846711Z",
     "iopub.status.busy": "2024-05-10T11:39:36.846341Z",
     "iopub.status.idle": "2024-05-10T11:39:36.851267Z",
     "shell.execute_reply": "2024-05-10T11:39:36.850240Z",
     "shell.execute_reply.started": "2024-05-10T11:39:36.846682Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragna import Rag\n",
    "from ragna.assistants import Gpt4, Gpt35Turbo16k\n",
    "from ragna.source_storages import Chroma, LanceDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de4c14ab-d1e6-4c0a-a060-7dbefe10de15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T11:39:37.096307Z",
     "iopub.status.busy": "2024-05-10T11:39:37.095945Z",
     "iopub.status.idle": "2024-05-10T11:39:37.101146Z",
     "shell.execute_reply": "2024-05-10T11:39:37.099934Z",
     "shell.execute_reply.started": "2024-05-10T11:39:37.096281Z"
    }
   },
   "outputs": [],
   "source": [
    "rag = Rag()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a4c3dc-2474-430c-be12-ec13b41458e0",
   "metadata": {},
   "source": [
    "### Step 3: Start chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f993c-3f5b-4973-bbec-27e17293d9c3",
   "metadata": {},
   "source": [
    "Ragna is async by design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eb51db8-c455-416e-acd5-0d6888fde5ad",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-05-10T11:39:38.601151Z",
     "iopub.status.busy": "2024-05-10T11:39:38.600287Z",
     "iopub.status.idle": "2024-05-10T11:39:40.430605Z",
     "shell.execute_reply": "2024-05-10T11:39:40.429390Z",
     "shell.execute_reply.started": "2024-05-10T11:39:38.601115Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content=How can I help you with the documents?, role=MessageRole.SYSTEM, sources=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = rag.chat(\n",
    "    documents=documents,\n",
    "    source_storage=Chroma,\n",
    "    assistant=Gpt4,\n",
    ")\n",
    "\n",
    "await chat.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0f42c-d1fc-4e0f-899f-83a1e156557d",
   "metadata": {},
   "source": [
    "### Step 4: Ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4cc2cf6-b464-46f4-91f5-c123be434035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T11:43:43.342644Z",
     "iopub.status.busy": "2024-05-10T11:43:43.342077Z",
     "iopub.status.idle": "2024-05-10T11:43:48.262947Z",
     "shell.execute_reply": "2024-05-10T11:43:48.261765Z",
     "shell.execute_reply.started": "2024-05-10T11:43:43.342611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Response: \n",
      "\n",
      "PyCon US 2024 will take place on the following dates:\n",
      "\n",
      "- Tutorials: May 15-16, 2024\n",
      "- Sponsor Presentations: May 16, 2024\n",
      "- Opening Reception: May 16, 2024\n",
      "- Main Conference and Online: May 17-19, 2024\n",
      "- Job Fair: May 19, 2024\n",
      "- Sprints: May 20-May 23, 2024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = await chat.answer(\"When is PyCon US 2024?\")\n",
    "print(f\"\\nLLM Response: \\n\\n{answer.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f4dab-4a4c-49af-92af-ab3fbd675169",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Let's check the sources used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e68c8887-b10d-4b21-bea1-fa950534387d",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-05-10T11:39:57.529956Z",
     "iopub.status.busy": "2024-05-10T11:39:57.529538Z",
     "iopub.status.idle": "2024-05-10T11:39:57.536446Z",
     "shell.execute_reply": "2024-05-10T11:39:57.535263Z",
     "shell.execute_reply.started": "2024-05-10T11:39:57.529925Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.: what-is-pycon-us.pdf, page(s) 1, 2\n",
      "\n",
      " host of events such as the Job Fair, Summits, Open Spaces,\n",
      "and PyLadies Auction, and donâ€™t forget about the â€˜hallwayâ€™ track, which brings\n",
      "together Python users from around the world.\n",
      "To include as many Python users as possible, PyCon US 2024 will offer the online\n",
      "attendance option again this year for anyone who cannot join us in person. PyCon US\n",
      "Online will include live streams of all talks and keynote sessions during the main\n",
      "conference days via the PyCon US 2024 virtual platform, Hubilo.\n",
      "PyCon US 2024 Dates:\n",
      "Tutorials - May 15-16, 2024\n",
      "Sponsor Presentations - May 16, 2024\n",
      "Opening Reception - May 16, 2024\n",
      "Main Conference and Online - May 17-19, 2024\n",
      "Job Fair - May 19, 2024\n",
      "Sprints - May 20-May 23, 2024\n",
      "Who attends PyCon US?\n",
      "PyCon US attracts a unique audience of Python users and community members, from\n",
      "beginners just learning the language to the leading developers in the field to\n",
      "community organizers to the contributors who guide the development of the\n",
      "language itself. Check out our 2023 recap\n",
      "(https://pycon.blogspot.com/2023/06/pycon-us-2023-recap-and-recording.html) to\n",
      "learn about who attended the last PyCon US.\n",
      "Every year, we hear from sponsors and other attendees that the people they meet at\n",
      "PyCon US are the most engaged conference audience theyâ€™ve encountered, that they\n",
      "have conversations there they donâ€™t have anywhere else, and that without\n",
      "exaggeration the course of their lives have been changed by encounters at the event.\n",
      "PyCon US is a diverse conference dedicated to providing an enjoyable experience to\n",
      "everyone. Help us ensure this by following our Code of Conduct (/2024/about/code-\n",
      "of-conduct/).\n",
      "Who makes PyCon US possible?\n",
      "PyCon US is the largest and longest-running annual gathering for the community\n",
      "using and developing the open-source Python programming language. It is produced\n",
      "and underwritten by the Python Software Foundation (https://www.python.org/psf-\n",
      "landing/), the 501(c)(3) nonprofit organization dedicated to advancing and promoting\n",
      "Python and its community. Through PyCon US, the PSF advances its mission of\n",
      "growing the international community of Python programmers.\n",
      "PyCon US\n",
      "################################################################################\n",
      "\n",
      "2.: what-is-pycon-us.pdf, page(s) 2, 3\n",
      "\n",
      "atta@python.org\n",
      "Olivia Sauls, Program Director - olivia@python.org\n",
      "Marisa Camacho, Community Events Coordinator - marisa@python.org\n",
      "Loren Crary, Sponsorships - sponsors@python.org\n",
      "About Pittsburgh, PA\n",
      "Visit https://www.visitpittsburgh.com/ (https://www.visitpittsburgh.com/) and the\n",
      "PyCon US Blog (https://pycon.blogspot.com/2020/12/announcing-pycon-us-\n",
      "20222023.html) for more information about Pittsburgh and all it has to offer!\n",
      "The PyCon US 2024 conference in Pittsburgh,\n",
      "Pennsylvania, USA is a production of the Python Software\n",
      "Foundation (https://www.python.org/psf/).\n",
      "This site is built using Django (https://www.djangoproject.com/) and Wagtail\n",
      "(https://wagtail.org/).\n",
      "PyCon US 2024 illustration and design by Anastasia B\n",
      "(https://www.linkedin.com/in/anastasiia-buhaienko-b12629183/) and Kyryl Ko\n",
      "(https://www.linkedin.com/in/kyrylo-kostritskiy-b1b7311b3/) of Awesomic Inc\n",
      "(https://www.awesomic.com/), Coordinated by Georgi K.\n",
      "Site design implemented by Kabu Creative (https://kabucreative.com/).\n",
      "Need help? Click here (/2024/about/support/) to find the correct person to\n",
      "contact.\n",
      "Privacy and Data policy (https://policies.python.org/us.pycon.org/Privacy-\n",
      "Policy/).\n",
      "\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, source in enumerate(answer.sources, 1):\n",
    "    print(f\"{idx}.: {source.document.name}, page(s) {source.location}\\n\")\n",
    "    print(source.content)\n",
    "    print(\"#\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3397e92f-d28b-4e6f-a21c-872bc2939221",
   "metadata": {},
   "source": [
    "#### Streaming answers\n",
    "\n",
    "Ragna allows you to stream the answers, one chunk at a time, just set `stream=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "465bd78f-b700-43ec-923c-13329e725f05",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-05-10T11:45:36.447727Z",
     "iopub.status.busy": "2024-05-10T11:45:36.446744Z",
     "iopub.status.idle": "2024-05-10T11:45:51.382181Z",
     "shell.execute_reply": "2024-05-10T11:45:51.380872Z",
     "shell.execute_reply.started": "2024-05-10T11:45:36.447693Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Response: \n",
      "\n",
      "\n",
      "At PyCon US 2024, you can expect an amazing program filled with pre-conference tutorials and sponsor presentations, over 90 talks from the community, including the Charlas track, keynote speakers, posters on display, and a lively Expo Hall filled with sponsors' booths. There will also be lightning talks on each main conference day. After the conference days, there will be 4 days of sprints that are free to all attendees and offer an opportunity for anyone to collaborate and contribute to a project, even if it's their first time. \n",
      "\n",
      "Other events include the Job Fair, Summits, Open Spaces, and PyLadies Auction. There's also the 'hallway' track, which brings together Python users from around the world. \n",
      "\n",
      "For those who cannot join in person, PyCon US 2024 will offer the online attendance option again this year. PyCon US Online will include live streams of all talks and keynote sessions during the main conference days via the PyCon US 2024 virtual platform, Hubilo. \n",
      "\n",
      "Here are the dates for PyCon US 2024:\n",
      "- Tutorials: May 15-16, 2024\n",
      "- Sponsor Presentations: May 16, 2024\n",
      "- Opening Reception: May 16,"
     ]
    }
   ],
   "source": [
    "answer = await chat.answer(\"What can I expect at PyCon US 2024?\", stream=True)\n",
    "\n",
    "print(f\"\\nLLM Response: \\n\\n\")\n",
    "      \n",
    "async for chunk in answer:\n",
    "    print(chunk, end= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b31dcb-6aa5-45df-b326-4b8dd7f0993f",
   "metadata": {},
   "source": [
    "#### Reducing hallucinations (errors)\n",
    "\n",
    "Ragna tries to ensure only the sources are used for answering questions.\n",
    "\n",
    "ðŸ”— [For reference, see Ragna source code on GitHub highlighting the prompt.](https://github.com/Quansight/ragna/blob/3cef0f7da1f2ed90e5d0618bcad82f824d00dc5a/ragna/assistants/_openai.py#L25-L26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35313b3f-913d-4393-b310-b1b866d4921e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T11:45:57.979263Z",
     "iopub.status.busy": "2024-05-10T11:45:57.978900Z",
     "iopub.status.idle": "2024-05-10T11:46:00.281206Z",
     "shell.execute_reply": "2024-05-10T11:46:00.280108Z",
     "shell.execute_reply.started": "2024-05-10T11:45:57.979237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Response: \n",
      "\n",
      "The text does not provide information on when the PyLadies lunch is scheduled.\n"
     ]
    }
   ],
   "source": [
    "answer = await chat.answer(\"When is the PyLadies lunch?\")\n",
    "print(f\"\\nLLM Response: \\n\\n{answer.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc06093-81ea-4a5f-a197-db25336698a5",
   "metadata": {},
   "source": [
    "### Advanced configuration\n",
    "\n",
    "`Rag().chat()` takes the following keyword arguments to help you optimize the quality of answers:\n",
    "\n",
    "* `chunk_size` - Size of each chunk (sections of the document that contain context) to use.\n",
    "* `chunk_overlap` - Size of the overlap with previous and next chunk for retrieving additional context for future prompts.\n",
    "* `num_tokens` - Maximum number of context tokens, and in turn the number of document chunks, pulled out of the vector database.\n",
    "\n",
    "You can also set these configurations in the web app (which we will see later)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fedd4e7-95a5-4cc3-a97f-a9ed7ea562b6",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "_â—ï¸ **Warning:** Make sure to stop the Jupyter Kernel (in the JupyterLab Menu Bar, click on \"Kernel\" -> \"Shut down Kernel\") before proceeding to prevent the \"insuffienct VRAM\" error._\n",
    "\n",
    "<br>\n",
    "\n",
    "**âœ¨ Next: [Use Local LLM with Ragna](03-RAG-local-llm.ipynb) â†’**\n",
    "\n",
    "<br>\n",
    "\n",
    "ðŸ’¬ _Wish to continue discussions after the tutorial? Contact the presenters: [@pavithraes](https://github.com/pavithraes), [@dharahs](https://github.com/dharahs), [@ahuang11](https://github.com/ahuang11)_\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb6a33-4511-42fe-a0fd-6670a0358047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peswaramoorthy@quansight.com-peswaramoorthy@quansight.com-pycon-de",
   "language": "python",
   "name": "conda-env-peswaramoorthy_quansight.com-peswaramoorthy_quansight.com-pycon-de-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
