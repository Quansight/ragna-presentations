{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15bbda72-2f2a-43d3-a3ed-b7f8c2f244a9",
   "metadata": {},
   "source": [
    "<img src=\"images/ragna-logo.png\" width=25% align=\"right\"/>\n",
    "\n",
    "# Basics of RAG-powered chat app\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba6e1b-e8ad-47c9-a9e4-48648fd476f1",
   "metadata": {},
   "source": [
    "## What is RAG?\n",
    "\n",
    "LLMs are trained on vast but static datasets:\n",
    "\n",
    "<img src=\"images/chatgpt-what-is-ragna-framework.png\" width=60%/>\n",
    "\n",
    "Search engines indexes the web and caught up pretty quickly:\n",
    "\n",
    "<img src=\"images/google-what-is-ragna-framework.png\" width=60%/>\n",
    "\n",
    "RAG is a method to augment foundational LLMs with fresh data and to reduce hallucinations and get around the limited space available in an LLM prompt (around 3,000 works for ChatGPT 3.5) \n",
    "\n",
    "<img src=\"images/RAG-new.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4e7b9-74fb-4325-adbd-ceb6f44eda45",
   "metadata": {},
   "source": [
    "TODO: Popular LLMs and source storage options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a1f1a5-cdef-4349-a69d-44cf0d81c487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## What is Ragna?\n",
    "\n",
    "Open source library for RAG Orchestration with a Python API, REST API, and web UI.\n",
    "\n",
    "TODO: Improve\n",
    "\n",
    "<img src=\"images/ragna-architecture.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafcd5d8-b9df-490d-a230-f0c4eb520d53",
   "metadata": {},
   "source": [
    "## Explore the Web UI\n",
    "\n",
    "TODO: Add instructions to open Ragna from Nebari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d45748-b244-4104-bc9a-3b744b4d10c9",
   "metadata": {},
   "source": [
    "## Build a chat function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f3695-9e43-4b1a-8d33-649f3c4449ec",
   "metadata": {},
   "source": [
    "### Step 1: Relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b187fe-31f6-449a-bfec-bc3398dd43af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "10-K reports from Ford, GM, and Tesla, as well as a file describing Ragna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9865ffb-8436-4856-a46a-6f4448ed7d37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragna is a new open source project built by Quansight. It is designed to allow organizations to explore the power of Retrieval-augmented generation (RAG) based AI tools. Ragna provides an intuitive API for quick experimentation and built-in tools for creating production-ready applications allowing you to quickly leverage Large Language Models (LLMs) for your work.\n",
      "\n",
      "At its core, Ragna is a plugin-based framework with a scalable queue based backend that provides:\n",
      "\n",
      " - Python API designed for experimentation that allows you to explore and test different LLMs, vector databases and embedding models quickly in Python.\n",
      "\n",
      "- A REST API that allows you to build custom RAG-based web applications for your particular needs.\n",
      "\n",
      "- A fully featured web application built with Panel (https://panel.holoviz.org) to select and configure LLMs, upload documents, and chat with the LLM. Designed for use as an out-of-the-box solution or as a reference to build custom web applications.\n",
      "\n",
      "The Ragna website is https://ragna.chat/\n",
      "Ragna's source code is available at https://github.com/Quansight/ragna\n",
      "Ragna is licensed under the BSD 3-Clause license\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"files/what-is-ragna.txt\",\n",
    "    \"files/ford-10k-2022.pdf\",\n",
    "    \"files/gm-10k-2022.pdf\",\n",
    "]\n",
    "\n",
    "print(open(documents[0], \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649a183-e6d9-4f92-96b1-c89d962fb3ca",
   "metadata": {},
   "source": [
    "### Step 2: Ragna configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9849b-bc6b-4899-a81c-16e131bea02b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Get an API key at https://platform.openai.com/api-keys\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=XXX # Export relevant API keys\n",
    "\n",
    "ragna init # Create ragna.toml config-file using CLI wizard\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae7dd0-bd7e-466d-bd47-7aa2a355e1a6",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "source": [
    "Using the configuration file, you can set the assistants, source storages, API endpoints, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e778ed8-3b35-48e0-9a01-ac17937b05fa",
   "metadata": {},
   "source": [
    "### Step 3: Select assistants and source storage\n",
    "\n",
    "ðŸ”— [Check the available assistants in the docs](https://ragna.chat/en/stable/generated/tutorials/gallery_python_api/#step-3-select-an-assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4d44b6-8d52-4e5e-a5e1-da566cea4407",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragna.assistants import Gpt35Turbo16k, GeminiPro\n",
    "from ragna.source_storages import Chroma, LanceDB\n",
    "\n",
    "from ragna import Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de4c14ab-d1e6-4c0a-a060-7dbefe10de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = Rag()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a4c3dc-2474-430c-be12-ec13b41458e0",
   "metadata": {},
   "source": [
    "### Step 4: Start chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eb51db8-c455-416e-acd5-0d6888fde5ad",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content=How can I help you with the documents?, role=MessageRole.SYSTEM, sources=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_gpt = rag.chat(documents=documents[:1], \n",
    "                source_storage=Chroma,\n",
    "                assistant=GeminiPro,\n",
    "                chunk_size=5,\n",
    "                chunk_overlap=5,\n",
    "               )\n",
    "\n",
    "await chat_gpt.prepare() # Ragna is async by design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0f42c-d1fc-4e0f-899f-83a1e156557d",
   "metadata": {},
   "source": [
    "### Step 5: Ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "465bd78f-b700-43ec-923c-13329e725f05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Response: \n",
      "\n",
      "The provided context does not contain the answer to this question.\n"
     ]
    }
   ],
   "source": [
    "answer = await chat_gpt.answer(\"What is Ragna?\")\n",
    "print(f\"\\nLLM Response: \\n\\n{answer.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f4dab-4a4c-49af-92af-ab3fbd675169",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Lets look at the sources used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e68c8887-b10d-4b21-bea1-fa950534387d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='de08ae93-ce9d-42f1-8b61-741f0a336a92' document=<ragna.core.LocalDocument object at 0x107ec91d0> location='' content=\"Ragna is a new open source project built by Quansight. It is designed to allow organizations to explore the power of Retrieval-augmented generation (RAG) based AI tools. Ragna provides an intuitive API for quick experimentation and built-in tools for creating production-ready applications allowing you to quickly leverage Large Language Models (LLMs) for your work.\\n\\nAt its core, Ragna is a plugin-based framework with a scalable queue based backend that provides:\\n\\n - Python API designed for experimentation that allows you to explore and test different LLMs, vector databases and embedding models quickly in Python.\\n\\n- A REST API that allows you to build custom RAG-based web applications for your particular needs.\\n\\n- A fully featured web application built with Panel (https://panel.holoviz.org) to select and configure LLMs, upload documents, and chat with the LLM. Designed for use as an out-of-the-box solution or as a reference to build custom web applications.\\n\\nThe Ragna website is https://ragna.chat/\\nRagna's source code is available at https://github.com/Quansight/ragna\\nRagna is licensed under the BSD 3-Clause license\\n\" num_tokens=239\n"
     ]
    }
   ],
   "source": [
    "print(answer.sources[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fedd4e7-95a5-4cc3-a97f-a9ed7ea562b6",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "**âœ¨ Next: TODO â†’**\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
